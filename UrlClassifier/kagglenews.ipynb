{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e45fa26c-5b46-d737-6486-2b7f4de1c915",
    "_uuid": "f52334cd42c7c21329bfa4e43d29c61884a96e47"
   },
   "source": [
    "The UCI ML News Aggregator Dataset contains headlines and categories for over 400k news articles. Let's see if we can accurately classify the news category based just on the headline.\n",
    "\n",
    "We'll use a [Multinomial Naive Bayes](https://en.wikipedia.org/wiki/Naive_Bayes_classifier) model to classify the headlines. Multinomial Naive Bayes models are provided in Python by the [scikit-learn library](http://scikit-learn.org/stable/modules/naive_bayes.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "a12bb00d-8b76-ef20-38fd-8777b9c10cba",
    "_uuid": "b8615508bf8654a3a2a9eb98600966a29a64ff26"
   },
   "outputs": [],
   "source": [
    "# get some libraries that will be useful\n",
    "import re\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# the Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# function to split the data for cross-validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "# function for transforming documents into counts\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# function for encoding categories\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# grab the data\n",
    "news = pd.read_csv(\"/home/hardik/PycharmProjects/DmNewsPopularity/datasets/uci-news-url.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "0db96719-79c5-b270-a349-ed9723f8b838",
    "_uuid": "a7143438aa670a4029dd4be52f9f0c91926d60b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>CATEGORY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fed official says weak data caused by weather,...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fed's Charles Plosser sees high bar for change...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US open: Stocks fall after Fed official hints ...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fed risks falling 'behind the curve', Charles ...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fed's Plosser: Nasty Weather Has Curbed Job Gr...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TITLE CATEGORY\n",
       "0  Fed official says weak data caused by weather,...        b\n",
       "1  Fed's Charles Plosser sees high bar for change...        b\n",
       "2  US open: Stocks fall after Fed official hints ...        b\n",
       "3  Fed risks falling 'behind the curve', Charles ...        b\n",
       "4  Fed's Plosser: Nasty Weather Has Curbed Job Gr...        b"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's take a look at our data\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "85c96bd1-f6ac-99c5-383d-8f6e84f9093e",
    "_uuid": "a23a2289e90614186d7ddd4682c26788bae1f65f"
   },
   "source": [
    "One thing we'll want to do is normalize the TITLE column a bit: remove punctuation and lowercase everything. This will give us a smaller set of words, which will decrease the size of our model, and ensure that words are treated the same even if they occur capitalized at the beginning of the headline or lowercase in the middle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "0e2df6cf-eee7-0e5c-9000-bf624af694fa",
    "_uuid": "26ec019c09ef43439d853df5f9bda9914ac41ff9"
   },
   "outputs": [],
   "source": [
    "def normalize_text(s):\n",
    "    s = s.lower()\n",
    "    \n",
    "    # remove punctuation that is not word-internal (e.g., hyphens, apostrophes)\n",
    "    s = re.sub('\\s\\W',' ',s)\n",
    "    s = re.sub('\\W\\s',' ',s)\n",
    "    \n",
    "    # make sure we didn't introduce any double spaces\n",
    "    s = re.sub('\\s+',' ',s)\n",
    "    \n",
    "    return s\n",
    "\n",
    "news['TEXT'] = [normalize_text(s) for s in news['TITLE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b016b879-d3d3-9214-4e05-58ac253c5c3d",
    "_uuid": "3169a861381636c648ceee7e6dc002e31a05103a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fed official says weak data caused by weather,...</td>\n",
       "      <td>b</td>\n",
       "      <td>fed official says weak data caused by weather ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fed's Charles Plosser sees high bar for change...</td>\n",
       "      <td>b</td>\n",
       "      <td>fed's charles plosser sees high bar for change...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US open: Stocks fall after Fed official hints ...</td>\n",
       "      <td>b</td>\n",
       "      <td>us open stocks fall after fed official hints a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fed risks falling 'behind the curve', Charles ...</td>\n",
       "      <td>b</td>\n",
       "      <td>fed risks falling behind the curve' charles pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fed's Plosser: Nasty Weather Has Curbed Job Gr...</td>\n",
       "      <td>b</td>\n",
       "      <td>fed's plosser nasty weather has curbed job growth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               TITLE CATEGORY  \\\n",
       "0  Fed official says weak data caused by weather,...        b   \n",
       "1  Fed's Charles Plosser sees high bar for change...        b   \n",
       "2  US open: Stocks fall after Fed official hints ...        b   \n",
       "3  Fed risks falling 'behind the curve', Charles ...        b   \n",
       "4  Fed's Plosser: Nasty Weather Has Curbed Job Gr...        b   \n",
       "\n",
       "                                                TEXT  \n",
       "0  fed official says weak data caused by weather ...  \n",
       "1  fed's charles plosser sees high bar for change...  \n",
       "2  us open stocks fall after fed official hints a...  \n",
       "3  fed risks falling behind the curve' charles pl...  \n",
       "4  fed's plosser nasty weather has curbed job growth  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2850722b-ed92-ef0b-04c9-84841b2b0512",
    "_uuid": "2424d78d5a7df85aa7c6d44c1ee10cc257b8aca5"
   },
   "source": [
    "Okay now let's get our data into a format where it will play nicely with the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "20de11e1-fddb-288f-de82-8a9cc15d9338",
    "_uuid": "98586346a4c2539268b1af18243559f1a8b70997"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(337935, 54636)\n",
      "(337935,)\n",
      "(84484, 54636)\n",
      "(84484,)\n"
     ]
    }
   ],
   "source": [
    "# pull the data into vectors\n",
    "vectorizer = CountVectorizer()\n",
    "x = vectorizer.fit_transform(news['TEXT'])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(news['CATEGORY'])\n",
    "\n",
    "# split into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# take a look at the shape of each of these\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bd9d43dd-c7c6-47ab-0c15-6dd14b495b93",
    "_uuid": "0d7633c2f2e39069e24ef0d95ac5aade40134303"
   },
   "source": [
    "So the x training vector contains 337935 observations of 54637 occurrences -- this latter number is the number of unique words in the entire collection of headlines. The x training vector contains the 337935 labels associated with each observation in the x training vector.\n",
    "\n",
    "So we're ready to go. Let's make the classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "971e7969-766c-e75b-4ae8-b09ce26b33df",
    "_uuid": "534e072095b1fb449617b355e89ade619d78b371"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e77ee291-1443-22fd-0f31-4405a4b271d1",
    "_uuid": "fbf67bc8226d249db2e9b1787558286442766eca"
   },
   "source": [
    "How well did it do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "62a469f2-6ac6-c5c5-a0c2-ccbd3e97489d",
    "_uuid": "c7c7b8b6d5d0a8dccda9e1b6e17ad263a6ce9d94"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 0, 3, 3, 0, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example=[\"amazon-instant-video-browser\",\"astronaut-notre-dame-bcs\",\"jobs-contently\",\"obama-boombox-israeli-radio-station-ad\",\"Google to launch Android SDK for wearables in two weeks\",\"US jobs growth last month hit by weather:Fed President Charles Plosser\",\"Apple versus Samsung case goes to California jury - WBAY\"]\n",
    "e=vectorizer.transform(example)\n",
    "nb.predict(e)\n",
    "#nb.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "246ecbbe-c3ae-13a9-74a3-cdeb4945443e",
    "_uuid": "7f6cfb03fad8b5f695eb237ad23be030aebfaa58"
   },
   "source": [
    "Nice! Over 92% accuracy, just by using words as independent features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4a02a410-2b9e-ee03-71d4-64770b47d161",
    "_uuid": "a9a2cff3f32b4fac959590d2d7c4f0d9d8a5b9f3"
   },
   "source": [
    "If you feel like exploring what words are characteristic of each category, you can pull out the coefficients of the Naive Bayes classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "05f9d835-3c91-d134-0462-b53ed30597ff",
    "_uuid": "01de23c5edb0e788e1fbf0698758c2b3081d40d7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coefs = nb.coef_\n",
    "print(coefs.shape)\n",
    "print(coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a2eedc65-df12-f305-a6bb-dd6a949094bb",
    "_uuid": "17d56e007d085f3311a3c2ca3e6d404b18efd2f4"
   },
   "source": [
    "That's a matrix of the log probability of each word given each category. The usual way to find characteristic words for a category is to take those words with the largest log odds ratio per category, which is an exercise left to the reader.\n",
    "\n",
    "The coefficients only give you log probabilities by index (which corresponds to whatever ordering the CountVectorizer decided on). To convert these indices back to words, you can pull out the vocabulary from the vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "425058d7-ca67-6f2f-cb18-8daec419a3d7",
    "_uuid": "40c48eae3780438a5b215980e4c71fe7d694d4a5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_reverse_vocabulary(vectorizer):\n",
    "    revvoc = {}\n",
    "\n",
    "    vocab = vectorizer.vocabulary_\n",
    "    for w in vocab:\n",
    "        i = vocab[w]\n",
    "\n",
    "        revvoc[i] = w\n",
    "\n",
    "    return revvoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0b88bad7-4612-f6a3-0fa4-8861ac2e6974",
    "_uuid": "573cca8bf0401001a1aa24ae5d542dff8f402cd9"
   },
   "source": [
    "And you can do something similar with the LabelEncoder to match the model's output classifications back to the dataset's categories. Again, this is left to the reader.\n",
    "\n",
    "I hope this was helpful in learning how to classify text! Possible next steps: \n",
    "- figure out the most characteristic words for each news category (someone please do this and report back!)\n",
    "- figure out how accurately we can classify particular news items (STORY in the dataset) given headline text"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 0,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
